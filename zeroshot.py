import torch
from PIL import Image
from transformers import AutoProcessor, AutoModel
import os
import json
import csv
from datetime import datetime
from name import text_prompts

def load_model_and_processor():
    """ëª¨ë¸ê³¼ í”„ë¡œì„¸ì„œë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ì‚¬ìš© ì¤‘ì¸ ë””ë°”ì´ìŠ¤: {device}")
    
    model = AutoModel.from_pretrained("openai/clip-vit-base-patch32", torch_dtype=torch.bfloat16, attn_implementation="sdpa")
    model = model.to(device)
    processor = AutoProcessor.from_pretrained("openai/clip-vit-base-patch32")
    return model, processor, device

def get_image_files(folder_path):
    """í´ë”ë³„ë¡œ ëª¨ë“  íŒŒì¼ì„ ì°¾ìŠµë‹ˆë‹¤."""
    folder_files = {}
    
    for root, dirs, files in os.walk(folder_path):
        folder_name = os.path.basename(root)
        if folder_name != "farm_insects":  # ë£¨íŠ¸ í´ë” ì œì™¸
            folder_files[folder_name] = []
            for file in files:
                folder_files[folder_name].append(os.path.join(root, file))
    
    # ê° í´ë” ë‚´ íŒŒì¼ë“¤ì„ ìì—°ìŠ¤ëŸ¬ìš´ ìˆ«ì ìˆœì„œë¡œ ì •ë ¬
    def natural_sort_key(filepath):
        import re
        filename = os.path.basename(filepath)
        return [int(text) if text.isdigit() else text.lower() for text in re.split('([0-9]+)', filename)]
    
    for folder_name in folder_files:
        folder_files[folder_name].sort(key=natural_sort_key)
    
    return folder_files

def classify_image(image_path, model, processor, text_prompts, device):
    """ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜í•©ë‹ˆë‹¤."""
    try:
        # ì´ë¯¸ì§€ ë¡œë“œ
        image = Image.open(image_path)
        
        # í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ ì²˜ë¦¬
        inputs = processor(text=text_prompts, images=image, return_tensors="pt", padding=True)
        
        # GPUë¡œ ì´ë™
        inputs = {k: v.to(device) for k, v in inputs.items()}
        
        # ëª¨ë¸ ì¶”ë¡ 
        with torch.no_grad():
            outputs = model(**inputs)
            logits_per_image = outputs.logits_per_image
            probs = logits_per_image.softmax(dim=1)
            most_likely_idx = probs.argmax(dim=1).item()
            most_likely_label = text_prompts[most_likely_idx]
            confidence = probs[0][most_likely_idx].item()
        
        return most_likely_label, confidence
    
    except Exception as e:
        print(f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {image_path}, ì˜¤ë¥˜: {e}")
        return None, 0.0

def extract_class_from_label(label):
    """ì˜ˆì¸¡ ê²°ê³¼ì—ì„œ í´ë˜ìŠ¤ëª…ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    # "a photo of adult Africanized Honey Bees (Killer Bees)" í˜•íƒœì—ì„œ í´ë˜ìŠ¤ëª… ì¶”ì¶œ
    if "a photo of" in label:
        # "a photo of" ì´í›„ì˜ ëª¨ë“  í…ìŠ¤íŠ¸ê°€ í´ë˜ìŠ¤ëª…
        parts = label.split("a photo of ")
        if len(parts) > 1:
            class_part = parts[1]
            # ì„±ì¥ë‹¨ê³„ ì œê±° (adult, larva, pupa, egg)
            growth_stages = ["adult ", "larva ", "pupa ", "egg "]
            for stage in growth_stages:
                if class_part.startswith(stage):
                    class_part = class_part[len(stage):]
                    break
            return class_part
    return label

def save_results(class_results, total_correct, total_files, overall_accuracy):
    """ê²°ê³¼ë¥¼ ë‹¤ì–‘í•œ í˜•ì‹ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')
    
    # ì „ì²´ í‰ê·  ì‹ ë¢°ë„ ê³„ì‚°
    all_confidences = []
    for class_name, results in class_results.items():
        for result in results:
            all_confidences.append(result['confidence'])
    overall_avg_confidence = sum(all_confidences) / len(all_confidences) if all_confidences else 0
    
    # ê²°ê³¼ ì €ì¥ í´ë” ìƒì„±
    results_dir = f"results"
    os.makedirs(results_dir, exist_ok=True)
    print(f"ğŸ“ ê²°ê³¼ ì €ì¥ í´ë” ìƒì„±: {results_dir}")
    
    # 1. JSON íŒŒì¼ë¡œ ìƒì„¸ ê²°ê³¼ ì €ì¥
    json_filename = os.path.join(results_dir, f"detailed_results.json")
    detailed_results = {
        'summary': {
            'total_files': total_files,
            'total_correct': total_correct,
            'overall_accuracy': overall_accuracy,
            'timestamp': timestamp
        },
        'class_results': class_results
    }
    
    with open(json_filename, 'w', encoding='utf-8') as f:
        json.dump(detailed_results, f, ensure_ascii=False, indent=2)
    print(f"ğŸ“„ ìƒì„¸ ê²°ê³¼ë¥¼ {json_filename}ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
    
    # 2. CSV íŒŒì¼ë¡œ ê°œë³„ ì´ë¯¸ì§€ ê²°ê³¼ ì €ì¥
    csv_filename = os.path.join(results_dir, f"individual_results.csv")
    with open(csv_filename, 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerow(['í´ë˜ìŠ¤', 'íŒŒì¼ëª…', 'ì˜ˆì¸¡_ë¼ë²¨', 'ì˜ˆì¸¡_í´ë˜ìŠ¤', 'ì‹ ë¢°ë„', 'ì •í™•_ì—¬ë¶€'])
        
        for class_name, results in class_results.items():
            for result in results:
                writer.writerow([
                    class_name,
                    result['file'],
                    result['predicted_label'] or 'ì‹¤íŒ¨',
                    result['predicted_class'] or 'ì‹¤íŒ¨',
                    result['confidence'],
                    'ì •í™•' if result['is_correct'] else 'ì˜¤ë¥˜'
                ])
    print(f"ğŸ“Š ê°œë³„ ê²°ê³¼ë¥¼ {csv_filename}ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
    
    # 3. ìš”ì•½ í†µê³„ CSV íŒŒì¼
    summary_filename = os.path.join(results_dir, f"summary_statistics.csv")
    with open(summary_filename, 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerow(['í´ë˜ìŠ¤', 'ì´_ì´ë¯¸ì§€ìˆ˜', 'ì •í™•_ê°œìˆ˜', 'ì •í™•ë„(%)', 'í‰ê· _ì‹ ë¢°ë„'])
        
        for class_name, results in class_results.items():
            correct_count = sum(1 for r in results if r['is_correct'])
            accuracy = (correct_count / len(results)) * 100 if results else 0
            avg_confidence = sum(r['confidence'] for r in results) / len(results) if results else 0
            
            writer.writerow([
                class_name,
                len(results),
                correct_count,
                f"{accuracy:.1f}",
                f"{avg_confidence:.3f}"
            ])
        
        # ì „ì²´ ìš”ì•½
        writer.writerow([])
        writer.writerow(['ì „ì²´', total_files, total_correct, f"{overall_accuracy:.1f}", f"{overall_avg_confidence:.3f}"])
    print(f"ğŸ“ˆ ìš”ì•½ í†µê³„ë¥¼ {summary_filename}ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
    
    # 4. í…ìŠ¤íŠ¸ ìš”ì•½ íŒŒì¼
    text_filename = os.path.join(results_dir, f"results_summary.txt")
    with open(text_filename, 'w', encoding='utf-8') as f:
        f.write("ì œë¡œìƒ· ë¶„ë¥˜ ê²°ê³¼ ìš”ì•½\n")
        f.write("=" * 50 + "\n")
        f.write(f"ì‹¤í–‰ ì‹œê°„: {timestamp}\n")
        f.write(f"ì „ì²´ ì •í™•ë„: {total_correct}/{total_files} ({overall_accuracy:.1f}%)\n")
        f.write(f"ì „ì²´ í‰ê·  ì‹ ë¢°ë„: {overall_avg_confidence:.3f}\n\n")
        
        for class_name, results in class_results.items():
            correct_count = sum(1 for r in results if r['is_correct'])
            accuracy = (correct_count / len(results)) * 100 if results else 0
            avg_confidence = sum(r['confidence'] for r in results) / len(results) if results else 0
            
            f.write(f"ğŸ“ {class_name}\n")
            f.write(f"   ì´ ì´ë¯¸ì§€ ìˆ˜: {len(results)}ê°œ\n")
            f.write(f"   ì •í™•ë„: {correct_count}/{len(results)} ({accuracy:.1f}%)\n")
            f.write(f"   í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.3f}\n\n")
    
    print(f"ğŸ“ í…ìŠ¤íŠ¸ ìš”ì•½ì„ {text_filename}ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
    
    # 5. README íŒŒì¼ ìƒì„±
    readme_filename = os.path.join(results_dir, "README.md")
    with open(readme_filename, 'w', encoding='utf-8') as f:
        f.write("# ì œë¡œìƒ· ë¶„ë¥˜ ê²°ê³¼\n\n")
        f.write(f"**ì‹¤í–‰ ì‹œê°„**: {timestamp}\n\n")
        f.write(f"**ì „ì²´ ì •í™•ë„**: {total_correct}/{total_files} ({overall_accuracy:.1f}%)\n")
        f.write(f"**ì „ì²´ í‰ê·  ì‹ ë¢°ë„**: {overall_avg_confidence:.3f}\n\n")
        f.write("## íŒŒì¼ ì„¤ëª…\n\n")
        f.write("- `detailed_results.json`: ëª¨ë“  ê²°ê³¼ì˜ ìƒì„¸ JSON ë°ì´í„°\n")
        f.write("- `individual_results.csv`: ê°œë³„ ì´ë¯¸ì§€ë³„ ë¶„ë¥˜ ê²°ê³¼\n")
        f.write("- `summary_statistics.csv`: í´ë˜ìŠ¤ë³„ í†µê³„ ìš”ì•½\n")
        f.write("- `results_summary.txt`: í…ìŠ¤íŠ¸ í˜•íƒœì˜ ê²°ê³¼ ìš”ì•½\n")
        f.write("- `README.md`: ì´ íŒŒì¼\n\n")
        f.write("## í´ë˜ìŠ¤ë³„ ì„±ëŠ¥\n\n")
        f.write("| í´ë˜ìŠ¤ | ì´ ì´ë¯¸ì§€ | ì •í™• ê°œìˆ˜ | ì •í™•ë„ | í‰ê·  ì‹ ë¢°ë„ |\n")
        f.write("|--------|-----------|-----------|--------|-------------|\n")
        
        for class_name, results in class_results.items():
            correct_count = sum(1 for r in results if r['is_correct'])
            accuracy = (correct_count / len(results)) * 100 if results else 0
            avg_confidence = sum(r['confidence'] for r in results) / len(results) if results else 0
            f.write(f"| {class_name} | {len(results)} | {correct_count} | {accuracy:.1f}% | {avg_confidence:.3f} |\n")
    
    print(f"ğŸ“– README íŒŒì¼ì„ {readme_filename}ì— ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
    print(f"\nğŸ’¾ ëª¨ë“  ê²°ê³¼ íŒŒì¼ì´ '{results_dir}' í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")

if __name__ == "__main__":
    # í´ë” ê²½ë¡œ ì„¤ì •
    folder_path = "/home/shinds/my_document/pest/farm_insects"
    
    # ëª¨ë¸ê³¼ í”„ë¡œì„¸ì„œ ë¡œë“œ (í•œ ë²ˆë§Œ)
    print("ëª¨ë¸ê³¼ í”„ë¡œì„¸ì„œë¥¼ ë¡œë“œí•˜ëŠ” ì¤‘...")
    model, processor, device = load_model_and_processor()
    
    # í´ë”ë³„ ì´ë¯¸ì§€ íŒŒì¼ë“¤ ì°¾ê¸°
    print("ì´ë¯¸ì§€ íŒŒì¼ë“¤ì„ ì°¾ëŠ” ì¤‘...")
    folder_files = get_image_files(folder_path)
    
    total_files = sum(len(files) for files in folder_files.values())
    print(f"ì´ {len(folder_files)}ê°œ í´ë”, {total_files}ê°œì˜ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
    
    # ê²°ê³¼ ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬
    class_results = {}
    
    # í´ë”ë³„ë¡œ ê°ê° ì²˜ë¦¬
    processed_count = 0
    for folder_name, image_files in folder_files.items():
        print(f"\n=== {folder_name} í´ë” ì²˜ë¦¬ ì¤‘ ===")
        class_results[folder_name] = []
        
        for i, image_path in enumerate(image_files):
            processed_count += 1
            print(f"ì²˜ë¦¬ ì¤‘: {processed_count}/{total_files} - {os.path.basename(image_path)}")
            
            label, confidence = classify_image(image_path, model, processor, text_prompts, device)
            
            if label:
                # ì˜ˆì¸¡ ê²°ê³¼ì—ì„œ í´ë˜ìŠ¤ëª…ë§Œ ì¶”ì¶œ
                predicted_class = extract_class_from_label(label)
                is_correct = predicted_class.lower() == folder_name.lower()
                
                print(f"ì‹¤ì œ í´ë˜ìŠ¤: {folder_name}")
                print(f"ì˜ˆì¸¡ ê²°ê³¼: {label}")
                print(f"ì¶”ì¶œëœ í´ë˜ìŠ¤: {predicted_class}")
                print(f"ì‹ ë¢°ë„: {confidence:.3f}")
                print(f"ê²°ê³¼: {'âœ… ì •í™•' if is_correct else 'âŒ ì˜¤ë¥˜'}")
                
                # ê²°ê³¼ ì €ì¥
                class_results[folder_name].append({
                    'file': os.path.basename(image_path),
                    'predicted_label': label,
                    'predicted_class': predicted_class,
                    'confidence': confidence,
                    'is_correct': is_correct
                })
            else:
                print("ë¶„ë¥˜ ì‹¤íŒ¨")
                class_results[folder_name].append({
                    'file': os.path.basename(image_path),
                    'predicted_label': None,
                    'predicted_class': None,
                    'confidence': 0.0,
                    'is_correct': False
                })
    
    # í´ë˜ìŠ¤ë³„ ê²°ê³¼ ìš”ì•½ ì¶œë ¥
    print("\n" + "="*50)
    print("í´ë˜ìŠ¤ë³„ ë¶„ë¥˜ ê²°ê³¼ ìš”ì•½")
    print("="*50)
    
    total_correct = 0
    total_files = 0
    
    for class_name, results in class_results.items():
        print(f"\nğŸ“ {class_name}")
        print(f"   ì´ ì´ë¯¸ì§€ ìˆ˜: {len(results)}ê°œ")
        
        # ì •í™•ë„ ê³„ì‚°
        correct_predictions = 0
        label_counts = {}
        
        for result in results:
            pred_label = result['predicted_label']
            
            # ì´ë¯¸ ì €ì¥ëœ predicted_class ì‚¬ìš©
            predicted_class = result['predicted_class']
            
            # ì‹¤ì œ í´ë˜ìŠ¤ì™€ ì˜ˆì¸¡ í´ë˜ìŠ¤ ë¹„êµ
            is_correct = predicted_class.lower() == class_name.lower() if predicted_class else False
            if is_correct:
                correct_predictions += 1
            
            # ì˜ˆì¸¡ ê²°ê³¼ ë¶„í¬ ê³„ì‚° (í´ë˜ìŠ¤ëª…ë§Œ ì‚¬ìš©)
            if predicted_class in label_counts:
                label_counts[predicted_class] += 1
            else:
                label_counts[predicted_class] = 1
        
        accuracy = (correct_predictions / len(results)) * 100 if results else 0
        total_correct += correct_predictions
        total_files += len(results)
        
        print(f"   âœ… ì •í™•ë„: {correct_predictions}/{len(results)} ({accuracy:.1f}%)")
        
        print("   ì˜ˆì¸¡ ê²°ê³¼ ë¶„í¬:")
        for label, count in sorted(label_counts.items(), key=lambda x: x[1], reverse=True):
            percentage = (count / len(results)) * 100
            # ì‹¤ì œ í´ë˜ìŠ¤ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í‘œì‹œ
            is_match = label.lower() == class_name.lower()
            match_indicator = "âœ…" if is_match else "âŒ"
            print(f"     {match_indicator} {label}: {count}ê°œ ({percentage:.1f}%)")
        
        # í‰ê·  ì‹ ë¢°ë„
        avg_confidence = sum(r['confidence'] for r in results) / len(results)
        print(f"   í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.3f}")
    
    # ì „ì²´ ì •í™•ë„
    overall_accuracy = (total_correct / total_files) * 100 if total_files > 0 else 0
    
    # ì „ì²´ í‰ê·  ì‹ ë¢°ë„ ê³„ì‚°
    all_confidences = []
    for class_name, results in class_results.items():
        for result in results:
            all_confidences.append(result['confidence'])
    overall_avg_confidence = sum(all_confidences) / len(all_confidences) if all_confidences else 0
    
    print(f"\n" + "="*50)
    print(f"ğŸ¯ ì „ì²´ ì •í™•ë„: {total_correct}/{total_files} ({overall_accuracy:.1f}%)")
    print(f"ğŸ¯ ì „ì²´ í‰ê·  ì‹ ë¢°ë„: {overall_avg_confidence:.3f}")
    print("="*50)
    
    print("\nëª¨ë“  ì´ë¯¸ì§€ ì²˜ë¦¬ ì™„ë£Œ!")
    
    # ê²°ê³¼ ì €ì¥
    save_results(class_results, total_correct, total_files, overall_accuracy)